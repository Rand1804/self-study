# [Asynchronous Programming in Rust](https://rust-lang.github.io/async-book/01_getting_started/01_chapter.html)

## Getting Started

Rust's implementation of async differs from most languages in a few ways:

- Futures are inert in Rust and make progress only when polled. Dropping a future stops it from making further progress.
- Async is zero-cost in Rust, which means that you only pay for what you use. Specifically, you can use async without heap allocations and dynamic dispatch, which is great for performance! This also lets you use async in constrained environments, such as embedded systems.
- No built-in runtime is provided by Rust. Instead, runtimes are provided by community maintained crates.
- Both single- and multithreaded runtimes are available in Rust, which have different strengths and weaknesses.

> In most traditional threaded applications, threads usually do consume heap memory. This is due to several factors:

> 1. **Thread Stack:** Every thread that is created requires its own separate stack space. This stack memory is allocated on the heap and its size can vary based on the thread requirements and system settings. Each thread's stack contains the local variables that are only visible to that particular thread.
> 2. **Thread Control Block (TCB):** The operating system maintains metadata for each thread in a structure known as the Thread Control Block. This data includes information like the thread ID, priority, and state (running, ready, blocked, etc.). The TCB is also stored on the heap.
> 3. **Dynamic dispatching:** In the context of your question, if an application uses dynamic dispatch (where the exact method to be called is determined at runtime), this could require heap allocations. These are often implemented through "virtual tables" or "vtables" that map a method call to the actual implementation at runtime.

> In the asynchronous version of the function described in your example, using `async`/`await` allows you to write asynchronous code that looks like synchronous code. The Rust async runtime manages all of the details for you.

> 1. **No separate thread stack:** Each async task does not require a separate stack. Instead, the state of the function is kept in a state machine generated by the compiler, and this state machine is stored in the heap memory once (at creation time of the future) and does not grow or shrink.
> 2. **Statically dispatched function calls:** With Rust's futures and async/await, the functions to be called are known at compile time (static dispatch), so there is no need for heap-allocated vtables.
> 3. **Efficient heap usage:** Though the state machine generated by async/await in Rust is stored on the heap, the memory allocation is typically more predictable and manageable compared to traditional threading. The memory usage tends to be more efficient because it's not allocating a large block of stack memory for each task.
> So, the claim "Additionally, all function calls are statically dispatched, and there are no heap allocations!" in your example should be understood in this nuanced way. It doesn't mean that there are no heap allocations at all, but rather that the allocations are more efficient and manageable compared to the traditional threading approach.

A few novel failure modes are possible in async Rust, for instance if you call a blocking function from an async context or if you implement the Future trait incorrectly.

async transforms a block of code into **a state machine** that implements a trait called Future.

### async/.await Primer

`async/.await` is Rust's built-in tool for writing asynchronous functions that look like synchronous code. async transforms a block of code into a state machine that implements a trait called Future. Whereas calling a blocking function in a synchronous method would block the whole thread, blocked Futures will yield control of the thread, allowing other Futures to run.

```rust
async fn do_something() { /* ... */ }
```

The value returned by async fn is a Future. For anything to happen, the Future needs to be run on an executor.

Inside an `async fn`, you can use `.await` to wait for the completion of another type that implements the `Future` trait, such as the output of another `async fn`.

Unlike `block_on`, `.await` doesn't block the current thread, but instead asynchronously waits for the future to complete, allowing other tasks to run if the future is currently unable to make progress.

```rust
async fn learn_and_sing() {
    // Wait until the song has been learned before singing it.
    // We use `.await` here rather than `block_on` to prevent blocking the
    // thread, which makes it possible to `dance` at the same time.
    let song = learn_song().await;
    sing_song(song).await;
}

async fn async_main() {
    let f1 = learn_and_sing();
    let f2 = dance();

    // `join!` is like `.await` but can wait for multiple futures concurrently.
    // If we're temporarily blocked in the `learn_and_sing` future, the `dance`
    // future will take over the current thread. If `dance` becomes blocked,
    // `learn_and_sing` can take back over. If both futures are blocked, then
    // `async_main` is blocked and will yield to the executor.
    futures::join!(f1, f2);
}

fn main() {
    block_on(async_main());
}
```

## Under the Hood: Executing Futures and Tasks

```rust
trait SimpleFuture {
    type Output;
    fn poll(&mut self, wake: fn()) -> Poll<Self::Output>;
}

enum Poll<T> {
    Ready(T),
    Pending,
}

```

Futures can be advanced by calling the poll function, which will drive the future as far towards completion as possible.

If the future completes, it returns Poll::Ready(result). If the future is not able to complete yet, it returns Poll::Pending and arranges for the wake() function to be called when the Future is ready to make more progress. When wake() is called, the executor driving the Future will call poll again so that the Future can make more progress.

```rust
pub struct SocketRead<'a> {
    socket: &'a Socket,
}

impl SimpleFuture for SocketRead<'_> {
    type Output = Vec<u8>;

    fn poll(&mut self, wake: fn()) -> Poll<Self::Output> {
        if self.socket.has_data_to_read() {
            // The socket has data -- read it into a buffer and return it.
            Poll::Ready(self.socket.read_buf())
        } else {
            // The socket does not yet have data.
            //
            // Arrange for `wake` to be called once data is available.
            // When data becomes available, `wake` will be called, and the
            // user of this `Future` will know to call `poll` again and
            // receive data.
            self.socket.set_readable_callback(wake);
            Poll::Pending
        }
    }
}
```

```rust
trait Future {
    type Output;
    fn poll(
        // Note the change from `&mut self` to `Pin<&mut Self>`:
        self: Pin<&mut Self>,
        // and the change from `wake: fn()` to `cx: &mut Context<'_>`:
        cx: &mut Context<'_>,
    ) -> Poll<Self::Output>;
}
```

The first change you'll notice is that our self type is no longer &mut Self, but has changed to Pin<&mut Self>. We'll talk more about pinning in a later section, but for now know that it allows us to create futures that are immovable. Immovable objects can store pointers between their fields, e.g. struct MyFut { a: i32, ptr_to_a: *const i32 }. Pinning is necessary to enable async/await.

Secondly, wake: fn() has changed to &mut Context<'_>. In SimpleFuture, we used a call to a function pointer (fn()) to tell the future executor that the future in question should be polled. However, since fn() is just a function pointer, it can't store any data about which Future called wake.

In a real-world scenario, a complex application like a web server may have thousands of different connections whose wakeups should all be managed separately. The Context type solves this by providing access to a value of type Waker, which can be used to wake up a specific task.

> In the context of asynchronous programming in Rust, a "task" is a top-level future that has been submitted to an executor. You can think of a task as a unit of work that the executor manages and schedules for execution.
An executor is a type of task scheduler. It is responsible for running tasks. Executors handle the low-level details of scheduling, including *managing threads*, handling I/O events, and waking up tasks when they're ready to make progress.
A future represents a computation that may not have completed yet. When a future is submitted to an executor, it becomes a task. The executor will repeatedly poll the task's future to try to make progress on it. When the future can't make progress (because it's waiting for I/O, a timer, or another future, for example), it can use a `Waker` to tell the executor to wake up the task later.
The `Waker` is passed to the future every time it's polled, and it's specific to the task. When the future is ready to make progress again, it can call `wake()` on the `Waker` to tell the executor to wake up the task. The executor will then start polling the task's future again.
So, in short, a "task" in Rust's async programming model is a future that's being managed by an executor, and it represents a unit of work that the executor should run.

Rust's Futures are lazy: they won't do anything unless actively driven to completion. One way to drive a future to completion is to .await it inside an async function, but that just pushes the problem one level up: who will run the futures returned from the top-level async functions? The answer is that we need a Future executor.

Future executors take a set of top-level Futures and run them to completion by calling poll whenever the Future can make progress. Typically, an executor will poll a future once to start off. When Futures indicate that they are ready to make progress by calling wake(), they are placed back onto a queue and poll is called again, repeating until the Future has completed.

### executor

Our executor will work by sending tasks to run over a channel. The executor will pull events off of the channel and run them. When a task is ready to do more work (is awoken), it can schedule itself to be polled again by putting itself back onto the channel.

### Executors and System IO

In practice, this problem is solved through integration with an IO-aware system blocking primitive, such as epoll on Linux, kqueue on FreeBSD and Mac OS, IOCP on Windows, and ports on Fuchsia (all of which are exposed through the cross-platform Rust crate `mio`).

## async/.await

```rust

// `foo()` returns a type that implements `Future<Output = u8>`.
// `foo().await` will result in a value of type `u8`.
async fn foo() -> u8 { 5 }

fn bar() -> impl Future<Output = u8> {
    // This `async` block results in a type that implements
    // `Future<Output = u8>`.
    async {
        let x: u8 = foo().await;
        x + 5
    }
}
```

As we saw in the first chapter, async bodies and other futures are *lazy*: they do nothing until they are run. The most common way to run a Future is to .await it. When .await is called on a Future, it will attempt to run it to completion. If the Future is blocked, it will yield control of the current thread. When more progress can be made, the Future will be picked up by the executor and will resume running, allowing the .await to resolve.

Unlike traditional functions, async fns which take references or other non-'static arguments return a Future which is bounded by the lifetime of the arguments:

```rust
// This function:
async fn foo(x: &u8) -> u8 { *x }

// Is equivalent to this function:
fn foo_expanded<'a>(x: &'a u8) -> impl Future<Output = u8> + 'a {
    async move { *x }
}
```

## Pinning

Pinning makes it possible to guarantee that an object implementing !Unpin won't ever be moved.
